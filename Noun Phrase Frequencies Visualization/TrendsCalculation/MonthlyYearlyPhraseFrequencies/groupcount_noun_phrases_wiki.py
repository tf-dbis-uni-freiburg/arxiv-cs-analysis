""" This module takes a pickle file containing a Pandas data frame of file wise total phrase frequencies. Each row in 
this data frame is identified by a unique arxiv_identifier, and also has a published date. The data in this dataframe
is grouped by month and 2 aggregates: sum (corresponding to the no. of phrases in that month) and count (corresponding
to the no. of documents  in that month) are calculated. The dates are converted into the correct format which is required
by a later module, and these are then converted to a JSON array of objects: one object for each of the above 2 aggregates.
This array of objects is finally stored in a JSON file."""
import pandas as pd
import json
import pickle

def create_monthly_grouped_df():
    """Unpickle the dataframe which contains filename, published date and num_phrases, group by published date,
    and calculate a count and a sum on num_phrases. Return the aggregates in a data frame"""
    # Unpickle data frame
    pickle_in = open('total_phrase_wiki_counter.pickle', "rb")
    df = pickle.load(pickle_in)
    # Change the index of the dataframe from the autogenerated index to the column published_date
    df.set_index('published_date', inplace=True)
    # Change the index to a datetime index
    df.index = pd.DatetimeIndex(df.index)
    # Create a new dataframe which is formed by grouping on the published_date index by month and calculating 2
    #  aggregates: 1. sum (which gives the no. of noun phrases in a given month) and 2. count (which gives the no. of documents in 
    # a given month). 
    # This also resets the index as a column and suitably renames columns.
    grouped_df = df.groupby(pd.Grouper(freq='1M')).num_phrase_urls.agg(['sum','count']).rename(columns={'sum': 'monthly_phrasefreq',
                                                                                            'count': 'monthly_docfreq'})
    # We don't need the day, only the month and the year -- format year-month. E.g. 2018-08.
    grouped_df.index = grouped_df.index.strftime('%Y-%m')
    # We need to transpose the df before calling to_json because it takes the column names as the keys of the JSON (same as to_dict).
    # After taking the transpose, the index values (date with year and month) become the columns and hence the keys in the JSON.
    # Write this to a JSON file: the json file will have a json array (python list) with 2 objects (dicts): one for the total
    # no. of phrases in each month, and one for the total no. of documents in each month.
    grouped_df.T.to_json('phrase_urls_and_docs_monthly.json', orient='records') 

if __name__ == '__main__':
    create_monthly_grouped_df()
